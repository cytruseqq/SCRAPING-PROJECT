# ğŸ•¸ï¸ Web Scraper Project (Distributed System)

> System rozproszonego scrapera stron internetowych z interfejsem webowym i architekturÄ… kontenerowÄ….

## ğŸ“Œ Opis projektu

Celem projektu byÅ‚o stworzenie systemu do scrapowania stron WWW, dziaÅ‚ajÄ…cego w architekturze rozproszonej. UÅ¼ytkownik, za pomocÄ… prostego interfejsu webowego, wprowadza adresy URL, ktÃ³re nastÄ™pnie sÄ… asynchronicznie przetwarzane przez silnik scrapujÄ…cy. Wyniki zapisywane sÄ… do bazy danych MongoDB.

## ğŸ›  Architektura systemu

Projekt skÅ‚ada siÄ™ z trzech niezaleÅ¼nych moduÅ‚Ã³w, uruchamianych w kontenerach Docker:

1. **Frontend (Flask + HTML/CSS)** â€“ formularz do wprowadzania adresÃ³w URL.
2. **Silnik scrapujÄ…cy (Python asyncio + multiprocessing)** â€“ przetwarza rÃ³wnolegle strony internetowe.
3. **Baza danych (MongoDB)** â€“ przechowuje artykuÅ‚y w formacie dokumentowym.

ğŸ“¦ CaÅ‚oÅ›Ä‡ zarzÄ…dzana jest przez `Docker Compose`.

## ğŸ§° Technologie

- **Python 3** (Flask, `aiohttp`, `BeautifulSoup`, `multiprocessing`)
- **HTML/CSS** (prosty frontend)
- **MongoDB**
- **Docker + Docker Compose**

## ğŸš€ Uruchomienie projektu

1. **Klonowanie repozytorium:**

```bash
git clone https://github.com/cytruseqq/SCRAPING_PROJECT.git
cd SCRAPING_PROJECT/web-scraper-project
```

2. **Uruchomienie aplikacji:**

```bash
docker-compose up --build
```

3. **DostÄ™p do aplikacji:**

OtwÃ³rz w przeglÄ…darce: [http://localhost:5001](http://localhost:5001)

## ğŸ“‹ Instrukcja uÅ¼ytkowania

1. WprowadÅº jeden lub wiÄ™cej adresÃ³w URL w formularzu.
2. Kliknij **"Start Scraping"**.
3. Aplikacja rozpocznie pobieranie danych, a komunikat **"OK â€“ scraping started"** potwierdzi dziaÅ‚anie.
4. Dane zostanÄ… zapisane w kolekcji `articles` w MongoDB.

## ğŸ§ª Testowanie

- System byÅ‚ testowany lokalnie na Windows z Docker Desktop.
- PoprawnoÅ›Ä‡ zapisu w MongoDB zostaÅ‚a potwierdzona przez **MongoDB Compass**.
- Scrapowanie przebiegaÅ‚o rÃ³wnolegle bez bÅ‚Ä™dÃ³w dla wielu adresÃ³w.

## ğŸ”® MoÅ¼liwoÅ›ci rozwoju

- ğŸ–¥ï¸ WyÅ›wietlanie wynikÃ³w w panelu webowym
- ğŸ•’ Automatyczne scrapowanie w zadanych odstÄ™pach (scheduler)
- ğŸ“¬ Kolejka zadaÅ„ (np. Redis + Celery)
- ğŸ¨ Usprawnienia UI/UX

## ğŸ§‘â€ğŸ’» Autorzy

- **Adrian WitÃ³w** â€“ 21319
- **Magdalena CzyÅ¼ewska** â€“ 21227  
Grupa: 3

## ğŸ”— Repozytorium

[https://github.com/cytruseqq/SCRAPING_PROJECT/tree/main/web-scraper-project](https://github.com/cytruseqq/SCRAPING_PROJECT/tree/main/web-scraper-project)

---

ğŸ“… **Data utworzenia raportu:** 11.05.2025